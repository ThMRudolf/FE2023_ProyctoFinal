---
title: "Final Fundamentos 2023"
authors: Ximena Paz, Thomas Rudolf
output:
  html_document: default
  pdf_document: default
editor_options:
  markdown:
    wrap: 72
---

Un reporte con las respuestas se deberá enviar por correo electrónico a
más tardar el martes 5 a las 21:00 horas.

Instrucciones:

-   En las siguientes preguntas describe tus procedimientos y escribe
    las respuestas explícitamente (que no haya necesidad de correr
    código para obtenerlas).

-   Incluye el código.

-   No está permitido discutir el exámen fuera de su equipo.

-   Para dudas (que no deben incluir info. de la respuesta) se
    preguntará en el canvas del grupo.

-   Consideren el material de visualización al hacer sus gráficas y
    reportar sus resultados.

```{r}
# activating libraries
library(tidyverse)
library(gt)
library(patchwork)
library(ggplot2)
```

## 1. Pruebas de hipótesis

1.1 De acuerdo a una encuesta en EUA, 26% de los residentes adultos de
Illinois han terminado la preparatoria. Un investigador sospecha que
este porcentaje es menor en un condado particular del estado. Obtiene
una muestra aleatoria de dicho condado y encuentra que 69 de 310
personas en la muestra han completado la preparatoria. Estos resultados
soportan su hipótesis? (describe tu elección de prueba de hipótesis,
valor p y conclusión).

*Pruebe de Hipothesis: Definicion* H0: La proporcion en el condado es
igual a la de la popalcion completa de Illenois.

H1: La proporcion en el condado es menor a la de la popalcion completa
de Illenois.

Vamos a hacer una pruebe de Wald porque estamos comparando dos
proporciones.

```{r}
# sample size
N = 310
# successes in %
p_hat <- 69/310
# % of succeses in complete population
p0 <- 0.26
# standard error
ee_pHat <- sqrt(p_hat*(1-p_hat)/N)
ee_p0<- sqrt(p0*(1-p0)/N)
# Wald test
W <- (p_hat-p0)/ee_pHat
# p value for one sided test
p <- (1 - pnorm(abs(W)))
result <- tibble(ssize = N, ee = ee_pHat, 
                 p0 = p0, 
                 p_hat = p_hat,
                 wald_test = W, 
                 p_value = p) %>% round(4)%>% gt() 
(result)
```

*Respuesta*: el valor p es 0.004 lo que nos lleva a la conclución que no
hay suficiente prueba para la H0 y la suspecha del investigador es
correcto.

1.2 Mendel criaba chícharos de semillas lisas amarillas y de semillas
corrugadas verdes. Éstas daban lugar a 4 tipos de descendientes:
amarrillas lisas, amarillas corrugadas, verdes lisas y verdes
corrugadas. El número de cada una es multinomial con parámetro
$p=(p_1, p_2, p_3, p_4)$. De acuerdo a su teoría de herencia este vector
de probabilidades es: $$p=(9/16,3/16,3/16,1/16)$$ A lo largo de $n=556$
experimentos observó $x=(315,101,108,32)$. Utiliza la prueba de cociente
de verosimilitudes para probar $H_0:p=p_0$ contra $H_0:p\ne p_0$.

1er paso: todo por separado: p1 con la prueba 1,etc.

```{r}
N = 556
p0=c(9/16,3/16,3/16,1/16)
x=c(315,101,108,32)
p_hat = x/N

log_verosim_4one <- function(p, n, N) {
  n*log(p)+(N-n)*log(1-p)
}

l_p1_hat <- log_verosim_4one(p_hat[1], x[1], sum(x))
l_p10 <- log_verosim_4one(p0[1], x[1], sum(x))

l_p2_hat <- log_verosim_4one(p_hat[2], x[2], sum(x))
l_p20 <- log_verosim_4one(p0[2], x[2], sum(x))

l_p3_hat <- log_verosim_4one(p_hat[3], x[3], sum(x))
l_p30 <- log_verosim_4one(p0[3], x[3], sum(x))

l_p4_hat <- log_verosim_4one(p_hat[4], x[4], sum(x))
l_p40 <- log_verosim_4one(p0[4], x[4], sum(x))

verosim_tbl <- tibble(p = seq(0.5, 0.6, 0.001)) %>% 
  mutate(log_verosim = log_verosim_4one(p, x[1], sum(x)))
  
  result_lambda <- tibble(lambda1 = 2*(l_p1_hat - l_p10), 
                          lambda2 = 2*(l_p2_hat - l_p20),
                          lambda3 = 2*(l_p3_hat - l_p30),
                          lambda4 = 2*(l_p4_hat - l_p40))
  result_lambda %>% gt()
```

ahora con multinominal:
$P=\frac{n!}{x_1!x_2!x_3!x_4!}p_1^{x_1}p_2^{x_2}p_3^{x_3}p_4^{x_4}$

ahora hacemos el log(P):
$log(P)=log(\frac{n!}{x_1!x_2!x_3!x_4!})+x_1log(p_1)+x_2log(p_2)+x_3log(p_3)+x_4log(p_4)$

la parte de $log(\frac{n!}{x_1!x_2!x_3!x_4!})$ no se necesita consider
ya que es una constant en ambas $Log()$. Usamos la funcion "mutinom()"

```{r}
x_observed <- c(315, 101, 108, 32)
p_hat <- x_observed/sum(x_observed)
# Parámetros bajo H0
p0 <- c(9/16, 3/16, 3/16, 1/16)

# Función de verosimilitud para una distribución multinomial
multinomial_likelihood <- function(p, x) {
  return(sum(dmultinom(x, size = sum(x), prob = p, log = TRUE)))
}

# Logaritmo de la función de verosimilitud bajo H0
log_likelihood_H0 <- multinomial_likelihood(p0, x_observed)

# Función de verosimilitud bajo H1 (usando los datos observados)
log_likelihood_H1 <- function(p) multinomial_likelihood(p, x_observed)

# Realizar la prueba de cociente de verosimilitudes
LR_statistic <- -2 * (log_likelihood_H0 - log_likelihood_H1(p_hat))

# Grados de libertad
df <- length(p0) - 1

# P-valor
p_value <- 1 - pchisq(LR_statistic, df)

# Imprimir resultados
cat("Estadístico de prueba (Lambda):", LR_statistic, "\n")
cat("Grados de libertad:", df, "\n")
cat("P-valor:", p_value, "\n")

result_lambda <- result_lambda %>% mutate(lambda_mn = LR_statistic) %>% gt() 
result_lambda
```

\

1.3. Sean $X_1, ...X_n \sim Poisson(\lambda)$,

-   Sea $\lambda_0>0$. ¿Cuál es la prueba Wald para
    $H_0: \lambda = \lambda_0, H_1: \lambda \neq \lambda_0$

$$
W_{Poisson}=\frac {(\lambda -\lambda_0)} {\sqrt(\frac{\lambda} {n})}
$$

-   Si $\lambda_0=1$, $n=20$ y $\alpha = 0.05$. Simula
    $X_1, ...X_n \sim Poisson(\lambda_0)$ y realiza la prueba Wald,
    repite 1000 veces y registra el porcentaje de veces que rechazas
    $H_0$, qué tan cerca te queda el error del tipo 1 de $0.05$?

```{r}
set.seed(123)
pois_rep <- function(lamb0, n){
  p <- rpois(n, lambda = lamb0)
  w <- (mean(p) - lamb0)/(sqrt(mean(p)/n))
  return(w)
}
n_reps = 1000
reps <- tibble(idx = 1:n_reps, w =map_dbl(1:n_reps, ~ pois_rep(1, 20))) 

count = 0
limit_p_value = 0.05
count_idx = array(0, dim=c(n_reps, 1))
p_value <- array(0, dim=c(n_reps, 1))
for(k in 1:length(reps$w)){
  p_value[k] <- 2*min(1-pnorm(abs(reps$w[k])))
  if(p_value[k]<limit_p_value){
    count = count + 1
    count_idx[count] = k
    #cat("fount a true\n")
    }
}
count_idx <- count_idx[1:count]
perc_err_tipio_1=count/n_reps
(perc_err_tipio_1)
p_values_err_tipo_1 <- p_value[count_idx[1:length(count_idx)]]
err_tipio_1_tbl <- tibble(err_tipo_1_mean = mean(p_values_err_tipo_1),
                          err_tipo_1_sd = sd(p_values_err_tipo_1), 
                          err_tipo_1_median = median(p_values_err_tipo_1),
                          perc_err_tipo_1 = perc_err_tipio_1) %>% gt()
(err_tipio_1_tbl)
```

## 2. Relación entre bootstrap e inferencia bayesiana

Consideremos el caso en que tenemos una única observación $x$
proveniente de una distribución normal

$$x \sim N(\theta, 1)$$

Supongamos ahora que elegimos una distribución inicial Normal.

$$\theta \sim N(0, \tau)$$

dando lugar a la distribución posterior (como vimos en la tarea)

$$\theta|x \sim N\bigg(\frac{x}{1 + 1/\tau}, \frac{1}{1+1/\tau}\bigg)$$

Ahora, entre mayor $\tau$, más se concentra la posterior en el estimador
de máxima verosimilitud $\hat{\theta}=x$. En el límite, cuando
$\tau \to \infty$ obtenemos una inicial no-informativa (constante) y la
distribución posterior

$$\theta|x \sim N(x,1)$$

Esta posterior coincide con la distribución de bootstrap paramétrico en
que generamos valores $x^*$ de $N(x,1)$, donde $x$ es el estimador de
máxima verosimilitud.

Lo anterior se cumple debido a que utilizamos un ejemplo Normal pero
también se cumple aproximadamente en otros casos, lo que conlleva a una
correspondencia entre el bootstrap paramétrico y la inferencia
bayesiana. En este caso, la distribución bootstrap representa
(aproximadamente) una distribución posterior no-informartiva del
parámetro de interés. Mediante la perturbación en los datos el bootstrap
aproxima el efecto bayesiano de perturbar los parámetros con la ventaja
de ser más simple de implementar (en muchos casos).\
\*Los detalles se pueden leer en *The Elements of Statistical Learning*
de Hastie y Tibshirani.

Comparemos los métodos en otro problema con el fin de apreciar la
similitud en los procedimientos:

Supongamos $x_1,...,x_n \sim N(0, \sigma^2)$, es decir, los datos
provienen de una distribución con media cero y varianza desconocida.

En los puntos 2.1 y 2.2 buscamos hacer inferencia del parámetro
$\sigma^2$.

2.1 Bootstrap paramétrico.

-   Escribe la función de log-verosimilitud y calcula el estimador de
    máxima verosimilitud para $\sigma^2$. Supongamos que observamos los
    datos `x` (en la carpeta datos), ¿Cuál es tu estimación de la
    varianza?

$L(\sigma^2)=\prod^{n}_{i=1} \frac{1}{\sqrt{2\pi\sigma^2}} \exp^{\frac{-(X_i-\hat{X})^2}{2 \sigma^2}}$

```         
```

La función de log-versosimilitud se define de esta manera:

$Log(L(\sigma^2))=-\frac{n}{2}log(2\pi)-\frac{n}{2}log(\sigma^2)-\frac{1}{2\sigma^2}\sum^n_{i=1}{(X_1-\hat{X})^2}$

Como estamos optimizando a travez de derivadas, podemo "neglegt" todos
lo constantes, ya que la derivada de una constante es igual a cero.
Adicionalmente sabemos que $\hat{X}$ es conocido y es igual a cero. De
esa manera se simplifica la formula:

$Log(L(\sigma^2))=-\frac{n}{2}log(\sigma^2)-\frac{1}{2\sigma^2}\sum^n_{i=1}{(X_i)^2}$

-   Aproxima el error estándar de la estimación usando **bootstrap
    paramétrico** y realiza un histograma de las replicaciones
    bootstrap.

```{r}
set.seed(312)
crear_log_sigma <- function(x){
  log_p <- function(pars){
    desv_est = pars[1]
    # ve la ecuación del ejercicio anterior
    z <- x / desv_est
    log_verosim <- -2*(log(desv_est) +  0.5 * mean(z^2))
    log_verosim
  }  
  log_p
}
load("data/x.RData")
log_p <- crear_log_sigma(x)
#optimize(verosim, c(-1000, 1000), maximum = TRUE)
res <- optim(0.5, log_p,lower = 0.001, upper = 100, control = list(fnscale = -1, maxit = 1000), method = "Brent")
res$convergence

est_mle <- tibble(parameter= c( "estimated sigma", "sigma sample", "difd sigma"), 
                  estimador = c( res$par, sd(x), res$par - sd(x))) %>% 
  column_to_rownames(var = "parameter")
est_mle
n_samples <- length(x)
sim_distr <- rnorm(n_samples, mean=0, sd=res$par)

x_sample <- tibble(x = x) %>% mutate(dist = "sample")
x_sample_opt_sigma <- tibble(x = sim_distr)%>% mutate(dist = "opt sigma")

plot_data <- bind_rows(x_sample, x_sample_opt_sigma)
ggplot(plot_data, aes(x = x, fill = dist)) +
  geom_histogram(aes(x = x), bins = 10, alpha = 0.5, position = "identity")
```

Bootstrap Parametrico:

```{r}
set.seed(312)
simular_modelo <- function(n, sigma){
  media = 0
  rnorm(n, media, sigma)
}
muestra_bootstrap <- simular_modelo(n_samples, 
                                    est_mle["sigma", "estimador"])
head(muestra_bootstrap)

# creamos nueva verosimilitud para muestra bootstrap
log_p_boot <- crear_log_sigma(muestra_bootstrap)
# optimizamos
res_boot <- optim(100, log_p_boot, lower = 0.001, upper = 100,
  control = list(fnscale = -1, maxit = 1000), method = "Brent")
res_boot$convergence

res_boot$par

```

```{r}
set.seed(312)
rep_boot <- function(rep, crear_log_fn, sigma, n){
  muestra_bootstrap <- simular_modelo(n, sigma)
  log_p_boot <- crear_log_fn(muestra_bootstrap)
  # optimizamos
  res_boot <- optim(100, log_p_boot, lower = 0.001, upper = 100,
  control = list(fnscale = -1, maxit = 1000), method = "Brent")
  try(if(res_boot$convergence != 0) stop("No se alcanzó convergencia."))
  tibble(parametro = c("sigma"), estimador_boot = res_boot$par) 
}
estim_sigma <-est_mle["estimated sigma", "estimador"]
reps_boot <- map_dfr(1:5000, ~ rep_boot(.x, 
                                        crear_log_fn = crear_log_sigma,
                                        sigma = estim_sigma, 
                                        n = n_samples)) 

ggplot(reps_boot, aes(x= estimador_boot)) + 
  geom_histogram() +
  labs(title="results of parametric bootstrap for sigma")
reps_boot_qq <- quantile(reps_boot$estimador_boot, c(0.025,0.5, 0.975))
reps_boot_qq 
result_boot <-tibble(ee_boot = sd(reps_boot$estimador_boot), 
                     mean_boot = mean(reps_boot$estimador_boot), 
                     low = mean_boot - 2*ee_boot,
                     up = mean_boot + 2*ee_boot)
result_boot %>% gt()
```

\
\
2.2 Análisis bayesiano

-   Continuamos con el problema de hacer inferencia de $\sigma^2$.
    Comienza especificando una inicial Gamma Inversa, justifica tu
    elección de los parámetros de la distribución inicial y grafica la
    función de densidad.

```{r}
set.seed(312)
# inicial value for a, and b
a <- 2
b <- 130
dist_inicial_tau <- rgamma(n_samples, a, b)
vari_init <- 1/sqrt(dist_inicial_tau)
# graficar para buscar los valores de a y b
g_dist_inicial <- ggplot(tibble(vari_init), aes(vari_init)) + geom_histogram() + labs(title="histogram to find a and b\n as close as possible to \n the prametric bootstrap")
density_gamma <-tibble(x = 1:n_samples, p=vari_init)
plot_g <- ggplot(density_gamma, aes(x=p)) + geom_density(fill = "skyblue", color= "black", alpha = 0.7)+
  labs(title ="inicial pdf of selected inverse \n gamma distribution,\n a = 2, b=130")
g_dist_inicial + plot_g

```

Con trial & error buscamos un valor que tiene un pico en un valor aprox
de la 11 (bootstrap parametrico nos dio un valor de 11.4) y con una
varianza no tan alta. Con eso llegamos a a=2 y b = 130.

-   Calcula analíticamente la distribución posterior.

![](P2.2_desarrollo_analitico_1.jpeg)

![](P2.2_desarrollo_analitico_2.jpeg)

![](P2.2_desarrollo_analitico_3.jpeg)

![](P2.2_desarrollo_analitico_4.jpeg)

La distribución posterior es una gama inversa con los parameteros
$\alpha = \alpha_{inicial}+\frac{n}{2}$ y
$\beta=\beta_{inicial}+\frac{n}{2} z$ y
$z=\frac{1}{n}\sum (x-\hat{x})^2$

-   Realiza un histograma de simulaciones de la distribución posterior y
    calcula el error estándar de la distribución.

```{r}
set.seed(312)
n_runs <- 5000
a_post <- a + n_runs/2 + 1
b_post <- b + n_runs/2 *(b/(a-1))
dist_post_vari <- sqrt(1/rgamma(n_samples, a_post, b_post))
ee_dist_post_vari <- sd(dist_post_vari)
mean_dist_post_vari <- mean(dist_post_vari)
dist_post_vari_tbl <- tibble(dist_post = dist_post_vari)
ggplot(dist_post_vari_tbl, aes(dist_post)) + geom_histogram()

result_bayesian <- dist_post_vari_tbl %>% summarise(ee_dist = sd(dist_post), 
                                  mean_dist = mean(dist_post), 
                                  low = mean_dist - 2*ee_dist, 
                                  up = mean_dist + 2*ee_dist)
(result_bayesian) %>% gt()
```

-   ¿Cómo se comparan tus resultados con los de bootstrap paramétrico?

*Respuestas*: Los resultados son parecdios: bootstrap parametrico llega
a un valor de 11.43339 y en la analisis bayesiano a un calor de 11.413.
Asi ambas methodos llegan a resultados parecidos que nos afirma mas que
le valor debe estar en este rango. El valor del resultado bayesiano se
encuentra dentro del intervalo de 95% del resultado bootstrap
parametrico, y el valor del resultado de bootstrap se encuentra en el
intervalo de bayesiano. *Nota*: Como le método bayesiano requiere cierto
conocimiento a priori como por ejemplo definir los parametros $a$ y $b$
y si estos valores están correctos, el metodo bayesiano es mas rapido y
menos costoso en sentido de costo computacional.

2.3 Supongamos que ahora buscamos hacer inferencia del parámetro
$\tau=log(\sigma)$, ¿cuál es el estimador de máxima verosimilitud?

la maxima verosimilitud es : $\tau = \prod {log(\sigma)}$ con
$\sigma = \sqrt{reps_boot$estimador_boot}$

-   con Utiliza bootstrap paramétrico para generar un intervalo de
    confianza del 95% para el parámetro $\tau$ y realiza un histograma
    de las replicaciones bootstrap.

```{r}
sigma <- (reps_boot$estimador_boot)
tau <- log(sigma)
ee_tau = sd(tau)
mean_tau = mean(tau)
result_confidence_interval <- tibble(interval=c("2.5%", "97.5%"),values=c(mean_tau-2*ee_tau, mean_tau+2*ee_tau)) 
result_confidence_interval %>% gt()
# histogram plot
hist_tbl <- tibble(tau = tau)
ggplot(hist_tbl, aes(x=tau) )+geom_histogram() +
  geom_vline(xintercept = result_confidence_interval$values[1]) +
  geom_vline(xintercept = result_confidence_interval$values[2]) +
  geom_vline(xintercept = mean_tau)
```

-   Ahora volvamos a inferencia bayesiana, calcula un intervalo de
    confianza para $\tau$ y un histograma de la distribución posterior
    de $\tau$.

```{r}
sigma_bay <- (dist_post_vari)
tau_bay <- log(sigma_bay)#*sigma_bay
ee_tau_bay <- sd(tau_bay)
mean_tau_bay <- mean(tau_bay)

result_confidence_interval_bay <- tibble(interval=c("2.5%", "97.5"),values=c(mean_tau_bay-2*ee_tau_bay, mean_tau_bay+2*ee_tau_bay)) 
result_confidence_interval_bay %>% gt()

# histogram plot
hist_tbl_bay <- tibble(tau = tau_bay)
ggplot(hist_tbl_bay, aes(x=tau_bay) )+geom_histogram() +
  geom_vline(xintercept = result_confidence_interval_bay$values[1]) +
  geom_vline(xintercept = result_confidence_interval_bay$values[2]) +
  geom_vline(xintercept = mean_tau_bay)

```

### 3. Bayesiana y regularización

Los datos *pew_research_center_june_elect_wknd_data.dta* tienen
información de ecnuestas realizadas durante la campaña presidencial 2008
de EUA.

```{r}
poll_data <- foreign::read.dta("data/pew_research_center_june_elect_wknd_data.dta")
```

-   Estima el porcentaje de la población de cada estado (excluyendo
    Alaska, Hawai, y DC) que se considera *very liberal*, utilizando el
    estimador de máxima verosimilitud.

```{r}
set.seed(1234)
pob_very_liberal <- poll_data |>
  filter(state %in% c("hawaii", "washington dc", "alaska") == FALSE) |>
  group_by(state) |>
  summarise(emv = mean(ideo == "very liberal", na.rm = TRUE))

pob_very_liberal %>% gt()

```

-   Grafica en el eje *x* el número de encuestas para cada estado y en
    el eje *y* la estimación de máxima verosimilitud para *very
    liberal*. ¿Qué observas?

```{r}
set.seed(1234)
pob_very_liberal <- poll_data |>
  filter(state %in% c("hawaii", "washington dc", "alaska") == FALSE) |>
  group_by(state) |>
  summarise(emv = mean(ideo == "very liberal", na.rm = TRUE), n = sum(!is.na(ideo)))

pob_very_liberal %>%
  ggplot(aes(x = n, y = emv, color = emv)) +
  geom_point()+
  labs(x="numero de encuestas", y="estimación max verosim (emv)")
```

*Observación:* Si el numero de encuestas es pequeño, el porcentage de
las personas que se consideran "very liberal" varia mucho. Eso es debido
a que hay poca información. Conforme se aumenta el numero de encuestas,
el valor se estabiliza en un valor intermedio.

-   Grafica en el eje *x* el porcentaje de votos que obtuvo Obama en la
    elección para cada estado y en el eje *y* la estimación de máxima
    verosimilitud para *very liberal*. ¿Qué observas? (usa los datos
    *2008ElectionResult.csv*)

```{r}
# read 
poll_obama <- read_csv("data/2008ElectionResult.csv")

pob_obama <- poll_obama %>%
  mutate(state = tolower(state)) %>%
  filter(!state %in% c("hawaii", "washington dc", "alaska")) %>%
  group_by(state) %>%
  summarise(vote_Obama_pct = mean(vote_Obama, na.rm = TRUE))


obama_very_liberal <- left_join(
  pob_obama,
  pob_very_liberal,
  by = "state",
  suffix = c("_obama", "_very_liberal")
)

obama_very_liberal %>%
  ggplot(aes(x = vote_Obama_pct, y = emv, color = emv)) +
  geom_point()+
  labs(x="numero de votos para Obama", y="estimación max verosim (emv)")

```

-   Estima el mismo porcentaje (*very liberal*) usando inferencia
    bayesiana, en particular la familia conjugada beta-binomial. Deberás
    estimar la proporción de manera independiente para cada estado, sin
    embargo, utilizarás la misma inicial a lo largo de todos:
    $Beta(8,160)$.

```{r}
pob_very_liberal <- poll_data |>
  filter(state %in% c("hawaii", "washington dc", "alaska") == FALSE) |>
  group_by(state) |>
  summarise(emv = mean(ideo == "very liberal", na.rm = TRUE), n = sum(!is.na(ideo)), k=sum(ideo == "very liberal", na.rm = TRUE))


# Parámetros de la distribución Beta
a <- 8
b <- 160

# Datos observados de la distribución Binomial
n <- pob_very_liberal$n
k <- pob_very_liberal$k

# Posterior
a_post <- a + k
b_post <- b + n - k

posterior_samples <- rbeta(5000, a_post, b_post)

beta_sims_inicial <- tibble(prop = rbeta(5000, a, b), dist = "inicial")
beta_sims_posterior <- tibble(prop = rbeta(5000, a_post, b_post), dist = "posterior")
bind_rows(beta_sims_inicial, beta_sims_posterior) %>% 
  ggplot(aes(x = prop, fill = dist)) +
    geom_histogram(alpha = 0.5, position = "identity") 

# Ahora lo sacarmeos por estado

posterior_samples_by_state <- data.frame(
  state = rep(unique(pob_very_liberal$state), each = 5000),
  posterior_samples = rbeta(length(unique(pob_very_liberal$state)) * 5000, a_post, b_post)
)

media_por_estado <- posterior_samples_by_state %>%
  group_by(state) %>%
  summarize(media_posterior = mean(posterior_samples))

```

```{r}

```

-   Simula de la distribución incial y describe.

```{r}
# Parámetros de la distribución Beta inicial
set.seed(123)

a <- 8
b <- 160
inicial_samples <- rbeta(5000, a, b)
quantile(inicial_samples, c(0.01, 0.05, 0.50, 0.90, 0.99)) |> round(3)

ggplot() +
  geom_histogram(aes(x = inicial_samples, y = ..density..), fill = "red", alpha = 0.7, bins = 30) +
  labs(x = "Proporción", y = "Densidad") +
  theme_minimal() +
  ggtitle("Distribución Inicial Beta")

```

-   Para dos de los estados: Idaho y Virginia, adicional a calcular la
    posterior usando las propiedades de la familia conjugada, utiliza
    Stan para hacer la inferencia, revisa los diagnósticos de
    convergencia y describe tus observaciones ($\hat{R}$ y $ESS$).

```{r}
install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
library(cmdstanr)
library(posterior)
library(tidyverse)

archivo_stan <- file.path("Stan.stan")
# compilar
mod <- cmdstan_model(archivo_stan)
mod

```

```{r}
#Idaho
datos_idaho <- pob_very_liberal %>% filter(state == "idaho")

# Datos 
datos_lista_idaho <- list(n = datos_idaho$n, y = datos_idaho$k)

# Ejecutar el modelo con los datos de Idaho
ajuste_idaho <- mod$sample(
  data = datos_lista_idaho,
  seed = 123,
  chains = 4,
  refresh = 500
)

ajuste_idaho$cmdstan_diagnose()

ajuste_idaho$summary()


```
Si son propiados ya que rhat está cercano a 1 y las muestras son cercanas a 1,500 por lo que si podríamos utilizarlas para Idaho 


```{r}
#Virginia
datos_virginia <- pob_very_liberal %>% filter(state == "virginia")

# Datos 
datos_lista_virginia <- list(n = datos_virginia$n, y = datos_virginia$k)

# Ejecutar el modelo con los datos de Virginia
ajuste_virginia <- mod$sample(
  data = datos_lista_virginia,
  seed = 123,
  chains = 4,
  refresh = 500
)

ajuste_virginia$cmdstan_diagnose()

ajuste_virginia$summary()
```

Si son propiados ya que rhat está cercano a 1 y las muestras son cercanas a 1,700 por lo que si podríamos utilizarlas para Idaho 


-   Utiliza la media posterior de cada estado como estimador puntual y
    repite las gráficas del inciso anterior.

```{r}
posterior_very_liberal <- left_join(
  media_por_estado,
  pob_very_liberal,
  by = "state",
  suffix = c("media_posterior", "very_liberal")
)

posterior_very_liberal %>%
  ggplot(aes(x = n, y = media_posterior, color = media_posterior)) +
  geom_point()
```
```{r}
posterior_obama_very_liberal <- left_join(
  pob_obama,
  posterior_very_liberal,
  by = "state",
  suffix = c("_obama", "_very_liberal")
)

posterior_obama_very_liberal %>%
  ggplot(aes(x = vote_Obama_pct, y = media_posterior, color = media_posterior)) +
  geom_point()
```

**Nota:** En problemas como este, donde estamos estimando un parámetro
para cada grupo (estado e nuestro caso) podemos optar por un modelo
jerárquico, en donde la distribución de las $\theta_j$ no esta dada por
la incial sino que se modela con un nivel adicional, cuyos parámetros se
estiman con los datos y tienen a su vez una distribución incial:

$$y_j|\theta_j \sim Binomial(n_j, \theta_j)$$

$$\theta_j \sim Beta(\alpha, \beta) $$

$$\alpha \sim g(a_o), \beta \sim f(b_0)$$

donde $g(a_0)$ y $f(b_0)$ son las inciales seleccionadas con
conocimiento experto.
